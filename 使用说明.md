# 文本相似度模型训练系统使用说明

## 📁 项目结构

```
audio_supportor/
├── core/                    # 核心训练脚本
│   ├── models/             # 模型定义
│   │   ├── __init__.py
│   │   ├── tfidf_lr_model.py   # TF-IDF + LR 模型类
│   │   ├── bert_model.py       # BERT 模型类
│   │   └── lstm_model.py       # Word2Vec + LSTM 模型类
│   ├── tfidf_lr_train.py   # TF-IDF + LR 模型训练
│   ├── bert_train.py       # BERT 模型训练
│   ├── lstm_train.py       # Word2Vec + LSTM 模型训练
│   ├── ensemble_train.py   # 模型集成
│   ├── run_all_models.py   # 一键运行所有模型
│   └── quick_test.py       # 快速测试脚本
├── data/                   # 数据目录
│   └── round1/            # 第一轮数据
│       ├── gaiic_track3_round1_train_20210228.tsv
│       └── gaiic_track3_round1_testA_20210228.tsv
├── results/               # 结果输出目录
├── requirements.txt       # Python依赖包
├── requirements_cpu.txt   # CPU版本依赖包
├── requirements_gpu.txt   # GPU版本依赖包
├── install_dependencies.py # 自动安装脚本
└── README_enhanced.md     # 技术文档
```

## 🚀 快速开始

### 0. 目录结构说明

项目采用了模块化的设计：
- `core/models/` - 包含所有模型的定义类
- `core/*_train.py` - 训练脚本，调用对应的模型类
- `data/` - 数据文件目录
- `results/` - 结果输出目录

这种设计使得：
- 模型定义和训练逻辑分离，便于维护
- 可以轻松添加新的模型
- 代码复用性更好

### 1. 环境准备

#### 方式一：自动安装（推荐）

运行自动安装脚本，它会检测您的环境并选择合适的版本：

```bash
python install_dependencies.py
```

#### 方式二：手动安装

根据您的环境选择合适的版本：

**CPU版本（推荐用于快速测试）：**
```bash
pip install -r requirements_cpu.txt
```

**GPU版本（推荐用于完整训练）：**
```bash
pip install -r requirements_gpu.txt
```

**通用版本（自动检测GPU）：**
```bash
pip install -r requirements.txt
```

**注意：** GPU版本需要先安装CUDA和cuDNN。

### 2. 快速测试

在运行完整训练之前，建议先运行快速测试脚本验证环境配置：

```bash
cd core
python quick_test.py
```

这个脚本会：
- 创建小样本测试数据
- 分别测试三个模型的基本功能
- 验证所有依赖是否正确安装
- 输出测试结果

如果所有模型都显示"✓ 测试通过"，说明环境配置正确。

### 3. 运行训练

#### 方式一：一键运行所有模型（推荐）

```bash
cd core
python run_all_models.py
```

这将依次训练：
1. TF-IDF + LR 模型
2. BERT 微调模型  
3. Word2Vec + LSTM 模型
4. 模型集成

#### 方式二：单独运行某个模型

```bash
cd core

# 只训练TF-IDF + LR
python tfidf_lr_train.py

# 只训练BERT
python bert_train.py

# 只训练Word2Vec + LSTM
python lstm_train.py
```

#### 方式三：跳过某些模型

```bash
cd core

# 跳过BERT训练（因为训练时间较长）
python run_all_models.py --skip bert

# 跳过多个模型
python run_all_models.py --skip bert lstm
```

#### 方式四：只运行集成

如果已经训练好了各个模型，只想重新进行集成：

```bash
cd core
python run_all_models.py --ensemble-only
```

## 📊 输出文件

训练完成后会在 `results/` 目录下生成：

### 单个模型结果
- `tfidf_lr_result.csv` - TF-IDF + LR 预测结果
- `bert_result.csv` - BERT 预测结果
- `lstm_result.csv` - Word2Vec + LSTM 预测结果

### 集成结果
- `simple_ensemble_result.csv` - 简单平均集成结果
- `weighted_ensemble_result.csv` - 加权平均集成结果
- `rank_ensemble_result.csv` - 排序集成结果
- `final_result.csv` - 最终提交结果（与原始格式一致）

### 模型文件
- `word2vec_model.model` - 训练好的Word2Vec模型

## 🎯 模型特点对比

| 模型 | 训练速度 | 内存需求 | 性能预期 | 适用场景 |
|------|----------|----------|----------|----------|
| TF-IDF + LR | 很快 | 低 | 中等 | 快速baseline，大数据集 |
| BERT | 很慢 | 高 | 高 | 小数据集，需要强语义理解 |
| Word2Vec + LSTM | 中等 | 中等 | 中高 | 中等数据集，平衡方案 |

## 🔧 高级用法

### 自定义集成权重

```bash
cd core

# 使用自定义权重进行加权集成
python ensemble_train.py --method weighted --weights 0.4 0.4 0.2
```

### 不同的集成方法

```bash
cd core

# 简单平均集成
python ensemble_train.py --method simple

# 加权平均集成
python ensemble_train.py --method weighted

# 排序集成
python ensemble_train.py --method rank
```

## ⚙️ 参数调优

### TF-IDF + LR 参数
在 `tfidf_lr_train.py` 中修改：
- `ngram_range`: n-gram范围
- `n_components`: SVD降维维度
- `C`: 逻辑回归正则化参数

### BERT 参数
在 `bert_train.py` 中修改：
- `max_len`: 文本最大长度
- `batch_size`: 批次大小
- `epochs`: 训练轮数
- `lr`: 学习率

### LSTM 参数
在 `lstm_train.py` 中修改：
- `embedding_dim`: 词向量维度
- `hidden_dim`: LSTM隐藏层维度
- `num_layers`: LSTM层数
- `max_len`: 序列最大长度

## ❓ 常见问题

### Q1: 训练时间太长怎么办？

**A:** 可以：
- 使用 `--skip` 参数跳过耗时模型
- 减少交叉验证折数（修改 `nfold` 参数）
- 减少训练轮数（修改 `epochs` 参数）
- 减小批次大小（修改 `batch_size` 参数）

### Q2: 内存不足怎么办？

**A:** 可以尝试：
- 减小 `max_len` 参数
- 减小 `batch_size`
- 使用CPU训练（修改device设置）
- 只运行轻量级模型（TF-IDF + LR）

### Q3: 如何只运行部分模型？

**A:** 使用 `--skip` 参数：
```bash
# 只运行TF-IDF + LR和LSTM
python run_all_models.py --skip bert

# 只运行BERT
python bert_train.py
```

### Q4: 如何自定义集成策略？

**A:** 修改 `ensemble_train.py` 中的权重：
```python
# 默认权重
default_weights = {
    'bert': 0.5,
    'lstm': 0.3,
    'tfidf_lr': 0.2
}
```

### Q5: 如何查看训练进度？

**A:** 每个脚本都会显示详细的训练进度，包括：
- 当前fold进度
- 每个epoch的loss和AUC
- 最终的平均性能

## 🔍 故障排除

### 错误1: CUDA out of memory
```
解决方案：减小batch_size或max_len
```

### 错误2: ModuleNotFoundError
```
解决方案：运行 pip install -r requirements.txt
```

### 错误3: 数据文件路径错误
```
解决方案：确保数据文件在 data/round1/ 目录下
```

### 错误4: BERT模型下载失败
```
解决方案：检查网络，或使用本地模型
```

## 📈 性能优化建议

### 1. 数据预处理优化
- 添加文本清洗步骤
- 使用更好的分词工具
- 添加同义词替换等数据增强

### 2. 模型优化
- 使用更先进的预训练模型（RoBERTa、ALBERT等）
- 尝试不同的网络架构（BERT-CNN、BERT-LSTM等）
- 使用学习率调度器

### 3. 集成优化
- 使用Stacking或Blending
- 基于验证集性能动态调整权重
- 添加更多模型（如XGBoost、LightGBM等）

## 📞 联系支持

如果遇到其他问题，请：
1. 先运行 `quick_test.py` 检查环境
2. 查看错误日志
3. 检查数据文件路径是否正确
4. 确认所有依赖包已正确安装

## 📝 更新日志

- v2.0: 重构为分离式文件结构，提高模块化程度
- v1.3: 优化内存使用和训练速度
- v1.2: 添加单独模型训练脚本
- v1.1: 添加快速测试脚本
- v1.0: 初始版本，包含三个基础模型 